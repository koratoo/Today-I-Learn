
### 📌 **기본 용어**
1. **머신러닝(Machine Learning, ML)** - 데이터에서 패턴을 학습하여 예측을 수행하는 알고리즘을 연구하는 분야.
2. **지도학습(Supervised Learning)** - 정답(라벨)이 있는 데이터를 학습하여 예측 모델을 만드는 방식.
3. **비지도학습(Unsupervised Learning)** - 정답(라벨) 없이 데이터를 학습하여 패턴을 찾는 방식.
4. **강화학습(Reinforcement Learning, RL)** - 환경과 상호작용하면서 보상을 극대화하는 방식으로 학습하는 방법.
5. **데이터셋(Dataset)** - 모델을 학습하는 데 사용하는 데이터의 집합.
6. **트레이닝 데이터(Training Data)** - 모델을 학습시키기 위해 사용하는 데이터.
7. **테스트 데이터(Test Data)** - 학습된 모델의 성능을 평가하기 위해 사용하는 데이터.
8. **검증 데이터(Validation Data)** - 하이퍼파라미터 튜닝을 위해 사용되는 데이터.

---

### 📌 **모델 관련 용어**
9. **특성(Feature)** - 머신러닝 모델이 학습하는 입력 변수.
10. **레이블(Label)** - 모델이 예측해야 하는 정답값.
11. **하이퍼파라미터(Hyperparameter)** - 학습 과정에서 조정해야 하는 변수 (예: 학습률, 은닉층 개수).
12. **가중치(Weight)** - 신경망에서 입력과 출력을 연결하는 값으로 학습을 통해 조정됨.
13. **편향(Bias)** - 신경망에서 가중치와 더불어 적용되는 보정 값.
14. **손실 함수(Loss Function)** - 모델의 예측값과 실제값의 차이를 측정하는 함수.
15. **최적화(Optimization)** - 모델의 손실을 최소화하기 위한 학습 과정.

---

### 📌 **머신러닝 알고리즘 관련 용어**
16. **회귀(Regression)** - 연속적인 값을 예측하는 지도학습 기법 (예: 선형 회귀).
17. **분류(Classification)** - 카테고리 또는 클래스를 예측하는 지도학습 기법 (예: 랜덤 포레스트, 로지스틱 회귀).
18. **군집화(Clustering)** - 데이터의 유사성을 기반으로 그룹을 찾는 비지도 학습 기법 (예: K-means).
19. **의사결정트리(Decision Tree)** - 데이터를 트리 형태로 분류하는 알고리즘.
20. **랜덤 포레스트(Random Forest)** - 여러 개의 의사결정트리를 조합하여 예측하는 알고리즘.
21. **서포트 벡터 머신(SVM, Support Vector Machine)** - 데이터를 고차원 공간으로 변환하여 분류하는 알고리즘.
22. **K-최근접 이웃(KNN, K-Nearest Neighbors)** - 가장 가까운 K개의 데이터를 기반으로 예측하는 알고리즘.
23. **신경망(Neural Network, NN)** - 인간의 뇌 신경망을 모방한 학습 모델.
24. **CNN(합성곱 신경망, Convolutional Neural Network)** - 이미지 처리에 특화된 신경망 구조.
25. **RNN(순환 신경망, Recurrent Neural Network)** - 시계열 데이터 및 자연어 처리에 적합한 신경망 구조.
26. **LSTM(Long Short-Term Memory)** - RNN의 장기 의존성 문제를 해결한 구조.

---

### 📌 **모델 평가 관련 용어**
27. **정확도(Accuracy)** - 전체 샘플 중 모델이 정답을 맞춘 비율.
28. **정밀도(Precision)** - 모델이 긍정(Positive)으로 예측한 것 중 실제로 긍정인 비율.
29. **재현율(Recall)** - 실제 긍정(Positive) 중에서 모델이 긍정으로 예측한 비율.
30. **F1-점수(F1 Score)** - 정밀도와 재현율의 조화 평균.
31. **ROC 곡선(ROC Curve)** - 분류 모델의 성능을 평가하는 그래프.
32. **AUC (Area Under Curve)** - ROC 곡선 아래 면적으로 모델의 분류 성능을 나타냄.
33. **과적합(Overfitting)** - 훈련 데이터에 너무 맞춰져 새로운 데이터에서 성능이 떨어지는 현상.
34. **과소적합(Underfitting)** - 모델이 데이터의 패턴을 충분히 학습하지 못한 상태.

---

### 📌 **딥러닝 학습 관련 용어**
35. **배치 정규화(Batch Normalization)** - 학습을 빠르게 하고 안정화하기 위한 기법.
36. **드롭아웃(Dropout)** - 과적합을 방지하기 위해 일부 뉴런을 랜덤하게 제거하는 기법.
37. **경사 하강법(Gradient Descent)** - 최적의 가중치를 찾기 위해 손실 함수를 최소화하는 알고리즘.
38. **확률적 경사 하강법(SGD, Stochastic Gradient Descent)** - 데이터 일부를 랜덤하게 선택하여 경사 하강법을 적용하는 방식.
39. **Adam 옵티마이저(Adam Optimizer)** - 경사 하강법을 개선한 최적화 알고리즘.

---

### 📌 **데이터 처리 및 전처리 관련 용어**
40. **원-핫 인코딩(One-Hot Encoding)** - 범주형 데이터를 벡터로 변환하는 방식.
41. **표준화(Standardization)** - 데이터를 평균 0, 분산 1로 변환하는 방식.
42. **정규화(Normalization)** - 데이터를 0~1 사이로 변환하는 방식.
43. **차원 축소(Dimensionality Reduction)** - 데이터의 차원을 줄여서 학습 속도를 향상하는 기법 (예: PCA).
44. **임베딩(Embedding)** - 고차원 데이터를 저차원으로 변환하는 기법 (예: 워드 임베딩).
