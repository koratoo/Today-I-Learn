머신러닝은 데이터를 학습시키는 방식에 따라 크게 **지도학습(Supervised Learning)**, **비지도학습(Unsupervised Learning)**, **강화학습(Reinforcement Learning)**으로 나뉩니다. 각 학습 방법을 차근차근 설명드리겠습니다.

---

### **1. 지도학습 (Supervised Learning)**

#### **개념**
- **입력 데이터(Input)**와 **정답(Label)**이 함께 제공되는 데이터로 모델을 학습시키는 방식입니다.
- 목표: 모델이 주어진 입력에 대해 올바른 출력을 예측하도록 학습.

#### **예시**
- **입력(Input)**: 어떤 집의 크기(50m²), 위치(도시 중심).
- **정답(Label)**: 해당 집의 가격(1억 원).
- 모델은 집 크기와 위치를 입력받아 가격을 예측하는 방법을 학습합니다.

#### **대표적인 문제 유형**
1. **분류(Classification)**:
   - 데이터를 특정 카테고리로 분류.
   - 예: 이메일이 스팸인지 아닌지 분류.
   - 알고리즘: 로지스틱 회귀, SVM, 랜덤 포레스트, 신경망 등.
   
2. **회귀(Regression)**:
   - 연속적인 값을 예측.
   - 예: 내일의 주식 가격, 집값 예측.
   - 알고리즘: 선형 회귀, 다중 회귀, 랜덤 포레스트, 신경망 등.

---

### **2. 비지도학습 (Unsupervised Learning)**

#### **개념**
- 정답(Label) 없이 입력 데이터만 가지고 학습.
- 목표: 데이터 내부의 패턴이나 구조를 발견.

#### **예시**
- 고객 데이터를 분석해 비슷한 구매 패턴을 가진 고객 그룹 찾기.
- 입력: 고객들의 구매 내역.
- 모델이 정답 없이 데이터를 분석해 "비슷한 고객"을 그룹화.

#### **대표적인 문제 유형**
1. **클러스터링(Clustering)**:
   - 데이터를 유사한 그룹으로 나눔.
   - 예: 고객 세분화, 유전자 그룹화.
   - 알고리즘: K-평균, DBSCAN, 계층적 클러스터링.
   
2. **차원 축소(Dimensionality Reduction)**:
   - 고차원 데이터를 저차원으로 변환.
   - 예: 이미지 압축, 데이터 시각화.
   - 알고리즘: PCA(주성분 분석), t-SNE.

3. **연관 규칙 학습(Association Rule Learning)**:
   - 데이터 간의 숨겨진 관계를 탐색.
   - 예: "우유를 산 고객은 빵도 살 가능성이 높다."
   - 알고리즘: Apriori, FP-Growth.

---

### **3. 강화학습 (Reinforcement Learning)**

#### **개념**
- 에이전트(Agent, 학습자)가 환경(Environment)과 상호작용하며 **보상(Reward)**을 최대화하는 행동 방식을 학습.
- 목표: 장기적으로 최대의 보상을 얻는 정책(Policy)을 학습.

#### **특징**
- 정답 데이터가 제공되지 않음.
- 에이전트는 자신이 취한 행동에 따라 **보상(Reward)** 또는 **페널티(Penalty)**를 받음.
- 주로 **순차적 의사결정 문제**에 사용.

#### **예시**
1. 게임 AI:
   - 체스, 바둑, 스타크래프트와 같은 게임에서 플레이 전략 학습.
   - 에이전트가 승리하면 보상을 받고, 패배하면 페널티를 받음.
2. 로봇 제어:
   - 로봇이 장애물을 피하며 목표 지점에 도달하도록 학습.
3. 자율 주행:
   - 도로 환경에서 충돌을 피하며 목적지까지 주행.

#### **구성 요소**
1. **상태(State)**: 현재 에이전트의 상태.
2. **행동(Action)**: 에이전트가 선택할 수 있는 행동.
3. **보상(Reward)**: 행동의 결과로 주어지는 점수.
4. **정책(Policy)**: 어떤 상태에서 어떤 행동을 취할지 결정하는 전략.

#### **알고리즘**
- **Q-Learning**: 보상을 기반으로 최적의 행동을 학습.
- **Deep Q-Learning**: Q-Learning에 딥러닝을 결합.
- **Policy Gradient**: 행동을 확률적으로 선택하는 정책을 학습.

---

### **비교 요약**
| 특징            | 지도학습                     | 비지도학습             | 강화학습                 |
|-----------------|---------------------------|-----------------------|-----------------------|
| **입력 데이터** | 입력과 정답(라벨) 제공        | 정답 없음              | 환경과 보상 제공        |
| **목표**        | 입력 → 정답 예측             | 데이터의 패턴 발견      | 보상을 최대화하는 행동 학습 |
| **알고리즘**    | 로지스틱 회귀, SVM, 신경망 등 | K-평균, PCA 등         | Q-Learning, Policy Gradient |
| **응용 분야**   | 이미지 분류, 가격 예측        | 고객 세분화, 차원 축소   | 게임 AI, 로봇 제어       |

---

### **사용 사례**
1. 지도학습:
   - 이메일 스팸 필터링
   - 의료 진단(암 여부 분류)
   
2. 비지도학습:
   - 추천 시스템 (비슷한 영화 추천)
   - 데이터 시각화
   
3. 강화학습:
   - 자율주행차
   - 게임 AI (알파고)

---

### **요약**
머신러닝의 학습 유형은 문제의 성격과 데이터를 어떻게 사용할지에 따라 달라집니다.  
